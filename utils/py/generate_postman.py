#!/usr/bin/env python3
"""
Unified Postman Collection Generator for KDF API

This script generates comprehensive Postman collections from KDF JSON files,
supporting both standard collections and environment-specific collections.

Features:
- Generates standard collections with full folder structure and validation
- Generates environment-specific collections (Native, WASM, Trezor variants)
- Parameter validation and reporting
- Protocol filtering for different environments
- Comprehensive CLI interface

Usage:
    python unified_postman_generator.py --help
"""

import json
import os
import sys
import uuid
import argparse
from pathlib import Path
from typing import Dict, List, Set, Any, Optional, Tuple
from datetime import datetime
import logging

# Add the lib directory to the path
sys.path.append(str(Path(__file__).parent / "lib"))

from managers.environment_manager import EnvironmentManager

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)


class UnifiedPostmanGenerator:
    """Unified generator for both standard and environment-specific Postman collections."""
    
    def __init__(self, workspace_root: Optional[str] = None):
        """Initialize the generator.
        
        Args:
            workspace_root: Path to the workspace root. If None, auto-detects.
        """
        if workspace_root is None:
            # Auto-detect workspace root from utils/py/ to workspace root
            workspace_root = Path(__file__).parent.parent.parent
        
        self.workspace_root = Path(workspace_root)
        self.requests_dir = self.workspace_root / "src" / "data" / "requests" / "kdf"
        self.responses_dir = self.workspace_root / "src" / "data" / "responses" / "kdf"
        self.tables_dir = self.workspace_root / "src" / "data" / "tables"
        
        # Initialize environment manager
        self.env_manager = EnvironmentManager()
        
        # Reports data
        self.unused_params = {}
        self.missing_responses = {}
        self.untranslated_keys = []
        self.missing_tables = []
        
        # Task ID variables for method groups
        self.task_variables = {}
        
        # Load configurations
        self.method_config = self.load_method_config()
        self.common_responses = self.load_common_responses()
    
    # ===== COMMON UTILITIES =====
    
    def load_json_file(self, file_path: Path) -> Optional[Dict]:
        """Load JSON file and return its content."""
        try:
            with open(file_path, 'r') as f:
                return json.load(f)
        except FileNotFoundError:
            logger.warning(f"File not found: {file_path}")
            return None
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in {file_path}: {e}")
            return None
    
    def load_method_config(self) -> Dict[str, Dict]:
        """Load method configuration from kdf_methods.json."""
        config_file = self.workspace_root / "src" / "data" / "kdf_methods.json"
        config = self.load_json_file(config_file)
        return config if config else {}
    
    def load_common_responses(self) -> Dict[str, Dict]:
        """Load common responses from common.json."""
        common_file = self.responses_dir / "common.json"
        common_responses = self.load_json_file(common_file)
        return common_responses if common_responses else {}
    
    def _is_manual_method(self, request_key: str) -> bool:
        """Check if a method requires manual intervention or external services."""
        manual_patterns = [
            "WalletConnect",  # Requires external wallet connection
            "Trezor",         # Requires hardware wallet
            "Metamask",       # Requires browser extension
            "Pin",            # Requires user PIN entry
            "UserAction"      # Requires user interaction
        ]
        
        return any(pattern in request_key for pattern in manual_patterns)
    
    def load_all_tables(self) -> Dict[str, Dict]:
        """Load all table files and combine them."""
        all_tables = {}
        
        # Load common structures
        common_dir = self.tables_dir / "common-structures"
        if common_dir.exists():
            for table_file in common_dir.glob("*.json"):
                tables = self.load_json_file(table_file)
                if tables:
                    all_tables.update(tables)
        
        # Load version-specific tables
        for version_dir in ["legacy", "v2"]:
            version_path = self.tables_dir / version_dir
            if version_path.exists():
                for table_file in version_path.glob("*.json"):
                    tables = self.load_json_file(table_file)
                    if tables:
                        all_tables.update(tables)
        
        return all_tables
    
    def load_request_data(self, version: str = "v2") -> Dict[str, Any]:
        """Load request data from JSON files."""
        request_file = self.requests_dir / version / "coin_activation.json"
        
        if not request_file.exists():
            raise FileNotFoundError(f"Request file not found: {request_file}")
        
        return self.load_json_file(request_file) or {}
    
    # ===== DATA PROCESSING UTILITIES =====
    
    def extract_method_name(self, method: str) -> str:
        """Extract method name from KDF method string."""
        return method.replace("::", "_")
    
    def get_method_path_components(self, method: str) -> List[str]:
        """Convert method name to folder path components."""
        if "::" in method:
            # For v2 methods like "task::enable_utxo::init"
            parts = method.split("::")
            return parts  # ["task", "enable_utxo", "init"]
        else:
            # For legacy methods like "enable"
            return [method]  # ["enable"]
    
    def get_method_group(self, request_key: str) -> str:
        """Extract method group from request key."""
        suffixes = ["Init", "Status", "UserAction", "Cancel"]
        group = request_key
        for suffix in suffixes:
            if group.endswith(suffix):
                group = group[:-len(suffix)]
                break
        return group
    
    def get_task_variable_name(self, method: str) -> str:
        """Generate task variable name from method."""
        if "::" in method:
            parts = method.split("::")
            if len(parts) >= 2:
                method_part = parts[1].replace("_", " ").title().replace(" ", "")
                return f"Task{method_part}_TaskId"
        return "DefaultTask_TaskId"
    
    def get_translated_name(self, request_key: str) -> str:
        """Get translated name for request key, fallback to original."""
        for method, config in self.method_config.items():
            # Skip deprecated methods
            if config.get('deprecated', False):
                continue
            examples = config.get("examples", {})
            if request_key in examples:
                return examples[request_key]
        
        if request_key not in self.untranslated_keys:
            self.untranslated_keys.append(request_key)
        return request_key
    
    # ===== DATA TRANSFORMATION =====
    
    def replace_userpass(self, data: Any) -> Any:
        """Replace userpass values with Postman variable."""
        if isinstance(data, dict):
            new_dict = {}
            for key, value in data.items():
                if key == "userpass" and value == "RPC_UserP@SSW0RD":
                    new_dict[key] = "{{ userpass }}"
                else:
                    new_dict[key] = self.replace_userpass(value)
            return new_dict
        elif isinstance(data, list):
            return [self.replace_userpass(item) for item in data]
        else:
            return data
    
    def replace_task_id(self, data: Any, task_var_name: str) -> Any:
        """Replace task_id values with Postman variable."""
        if isinstance(data, dict):
            new_dict = {}
            for key, value in data.items():
                if key == "task_id" and isinstance(value, int):
                    new_dict[key] = f"{{{{ {task_var_name} }}}}"
                else:
                    new_dict[key] = self.replace_task_id(value, task_var_name)
            return new_dict
        elif isinstance(data, list):
            return [self.replace_task_id(item, task_var_name) for item in data]
        else:
            return data
    
    # ===== ENVIRONMENT-SPECIFIC FILTERING =====
    
    def filter_protocols_for_environment(self, request_data: Dict[str, Any], 
                                       environment: str) -> Dict[str, Any]:
        """Filter and update protocol configurations for specific environment."""
        filtered_data = json.loads(json.dumps(request_data))  # Deep copy
        
        # Parse environment components
        env_parts = environment.split('_')
        base_env = env_parts[0]  # native, wasm
        wallet_type = env_parts[1] if len(env_parts) > 1 and env_parts[1] in ['hd', 'iguana'] else None
        
        for request_key, request_body in filtered_data.items():
            if not isinstance(request_body, dict):
                continue
            
            params = request_body.get('params', {})
            method = request_body.get('method', '')
            
            # Handle electrum servers
            self._update_electrum_servers(params, base_env)
            
            # Handle WebSocket URLs
            self._update_websocket_urls(params, base_env)
            
            # Handle nodes for ETH/Tendermint
            self._update_node_urls(params, base_env)
            
            # Handle wallet type specific parameters
            self._update_wallet_type_params(params, method, wallet_type)
        
        return filtered_data
    
    def _update_electrum_servers(self, params: Dict[str, Any], environment: str):
        """Update electrum server configurations for environment."""
        # Handle nested electrum servers (UTXO coins)
        if 'mode' in params and 'rpc_data' in params['mode']:
            rpc_data = params['mode']['rpc_data']
            if 'servers' in rpc_data:
                rpc_data['servers'] = self._filter_electrum_servers(
                    rpc_data['servers'], environment
                )
        
        # Handle direct electrum servers (Z-coins)
        if 'electrum_servers' in params:
            params['electrum_servers'] = self._filter_electrum_servers(
                params['electrum_servers'], environment
            )
    
    def _filter_electrum_servers(self, servers: List[Dict], environment: str) -> List[Dict]:
        """Filter electrum servers based on environment protocol preferences."""
        if environment == 'wasm':
            # WASM only supports WSS
            return [s for s in servers if s.get('protocol') == 'WSS']
        elif environment == 'native':
            # Native prefers TCP and SSL, but can use WSS
            preferred_order = ['TCP', 'SSL', 'WSS']
            sorted_servers = []
            for protocol in preferred_order:
                sorted_servers.extend([s for s in servers if s.get('protocol') == protocol])
            return sorted_servers[:3]  # Limit to 3 servers
        else:
            return servers
    
    def _update_websocket_urls(self, params: Dict[str, Any], environment: str):
        """Update WebSocket URLs for environment."""
        if environment == 'wasm':
            # Ensure all WebSocket URLs use WSS
            for key in ['nodes', 'ws_url']:
                if key in params:
                    if key == 'nodes' and isinstance(params[key], list):
                        for node in params[key]:
                            if 'ws_url' in node and node['ws_url'].startswith('ws://'):
                                node['ws_url'] = node['ws_url'].replace('ws://', 'wss://')
    
    def _update_node_urls(self, params: Dict[str, Any], environment: str):
        """Update node URLs for environment preferences."""
        if 'nodes' in params and isinstance(params['nodes'], list):
            for node in params['nodes']:
                if environment == 'wasm':
                    if 'ws_url' in node and not node['ws_url'].startswith('wss://'):
                        if node['ws_url'].startswith('ws://'):
                            node['ws_url'] = node['ws_url'].replace('ws://', 'wss://')
    
    def _update_wallet_type_params(self, params: Dict[str, Any], method: str, wallet_type: str):
        """Update parameters based on wallet type requirements."""
        if wallet_type is None:
            return
        
        if wallet_type == 'iguana':
            # Remove HD-only parameters for Iguana wallet
            hd_only_params = self.env_manager.get_conditional_params(method, 'hd')
            for param in hd_only_params:
                if param in params:
                    del params[param]
    
    # ===== VALIDATION =====
    
    def validate_request_params(self, request_data: Dict, method: str, tables: Dict[str, Dict]) -> Set[str]:
        """Validate request parameters against table definitions and return unused params."""
        if method not in self.method_config:
            logger.warning(f"No method config found for method: {method}")
            return set()
        
        table_name = self.method_config[method].get("table")
        if not table_name or table_name not in tables:
            logger.warning(f"Table {table_name} not found for method {method}")
            return set()
        
        table_params = set()
        for param_def in tables[table_name].get("data", []):
            table_params.add(param_def["parameter"])
        
        # Extract request parameters
        request_params = set()
        params_data = request_data.get("params", {})
        
        if "activation_params" in params_data:
            # Add top-level params
            for key in params_data.keys():
                if key != "activation_params":
                    request_params.add(key)
            # Extract nested parameters
            self._extract_param_names(params_data["activation_params"], request_params)
        else:
            self._extract_param_names(params_data, request_params)
        
        unused_params = table_params - request_params
        if unused_params:
            logger.warning(f"Unused parameters in {method}: {unused_params}")
        
        return unused_params
    
    def _extract_param_names(self, data: Any, param_names: Set[str], prefix: str = "") -> None:
        """Recursively extract parameter names from request data."""
        if isinstance(data, dict):
            for key, value in data.items():
                if key in ["userpass", "mmrpc", "method"]:
                    continue
                
                param_key = f"{prefix}.{key}" if prefix else key
                param_names.add(param_key)
                
                if isinstance(value, dict):
                    self._extract_param_names(value, param_names, param_key)
                elif isinstance(value, list) and value and isinstance(value[0], dict):
                    self._extract_param_names(value[0], param_names, param_key)
    
    def check_response_exists(self, request_key: str, version: str) -> bool:
        """Check if response file exists for the request and has actual content."""
        response_file = self.responses_dir / version / "coin_activation.json"
        if not response_file.exists():
            return False
        
        response_data = self.load_json_file(response_file)
        if not response_data:
            return False
        
        if request_key not in response_data:
            return False
        
        # Resolve any common response references
        response_value = response_data[request_key]
        resolved_response = self.resolve_response_reference(response_value, self.common_responses)
        
        if resolved_response is None:
            return False
        
        # Check if response has actual content (not just empty templates)
        if isinstance(resolved_response, dict):
            # Check for success and error arrays
            success_responses = resolved_response.get("success", [])
            error_responses = resolved_response.get("error", [])
            
            # If both arrays are empty, consider this as missing response
            if (isinstance(success_responses, list) and len(success_responses) == 0 and 
                isinstance(error_responses, list) and len(error_responses) == 0):
                return False
        
        return True
    
    def resolve_response_reference(self, response_value: Any, common_responses: Dict[str, Dict]) -> Any:
        """Resolve response references to common responses."""
        if isinstance(response_value, str) and response_value in common_responses:
            return common_responses[response_value]
        elif isinstance(response_value, list):
            resolved_list = []
            for item in response_value:
                if isinstance(item, str) and item in common_responses:
                    resolved_list.append(common_responses[item])
                else:
                    resolved_list.append(item)
            return resolved_list
        else:
            return response_value
    
    # ===== TABLE GENERATION =====
    
    def generate_table_markdown(self, method: str, tables: Dict[str, Dict]) -> str:
        """Generate markdown table from table data for method."""
        if method not in self.method_config:
            if method not in self.missing_tables:
                self.missing_tables.append(method)
            return ""
        
        table_name = self.method_config[method].get("table")
        if not table_name or table_name not in tables:
            if method not in self.missing_tables:
                self.missing_tables.append(method)
            return ""
        
        table_data = tables[table_name].get("data", [])
        if not table_data:
            if method not in self.missing_tables:
                self.missing_tables.append(method)
            return ""
        
        # Generate markdown table
        markdown = "## Request Parameters\n\n"
        markdown += "| Parameter | Type | Description |\n"
        markdown += "|-----------|------|-------------|\n"
        
        for param in table_data:
            parameter = param.get("parameter", "")
            param_type = param.get("type", "")
            required = param.get("required", False)
            default = param.get("default", "")
            description = param.get("description", "")
            
            # Build the type column with required/default info
            type_column = param_type
            if required and default:
                type_column += f" (required. Default: `{default}`)"
            elif required:
                type_column += " (required)"
            elif default:
                type_column += f" (Default: `{default}`)"
            
            # Escape markdown characters
            description = description.replace("|", "\\|").replace("\n", " ")
            
            markdown += f"| `{parameter}` | {type_column} | {description} |\n"
        
        return markdown
    
    # ===== POSTMAN REQUEST CREATION =====
    
    def create_postman_request(self, request_key: str, request_data: Dict, 
                             version: str, tables: Dict[str, Dict], 
                             method_examples: List[tuple] = None,
                             environment: str = None) -> Dict:
        """Create a Postman request object."""
        method = request_data.get("method", "unknown")
        
        # Get translated name
        if method_examples and len(method_examples) > 1:
            translated_name = method
        else:
            translated_name = self.get_translated_name(request_key)
        
        # Add environment suffix for environment-specific collections
        if environment and environment != "standard":
            env_suffix = environment.replace('_', ' ').title()
            if env_suffix not in translated_name:
                translated_name += f" ({env_suffix})"
        
        # Handle task_id variables
        task_var_name = None
        if "task_id" in json.dumps(request_data):
            task_var_name = self.get_task_variable_name(method)
            self.task_variables[task_var_name] = "1"
        
        # Replace userpass and task_id
        processed_data = self.replace_userpass(request_data)
        if task_var_name:
            processed_data = self.replace_task_id(processed_data, task_var_name)
        
        # Generate description with table markdown
        description = self.generate_table_markdown(method, tables)
        
        # Add environment-specific description notes
        if environment:
            description += self._generate_environment_notes(environment, method)
        
        # Add examples if there are multiple variants
        examples = []
        if method_examples and len(method_examples) > 1:
            for example_key, example_data in method_examples:
                example_name = self.get_translated_name(example_key)
                processed_example = self.replace_userpass(example_data)
                if task_var_name:
                    processed_example = self.replace_task_id(processed_example, task_var_name)
                
                examples.append({
                    "name": example_name,
                    "originalRequest": {
                        "method": "POST",
                        "header": [{"key": "Content-Type", "value": "application/json"}],
                        "body": {
                            "mode": "raw",
                            "raw": json.dumps(processed_example, indent=2)
                        },
                        "url": {
                            "raw": "{{base_url}}",
                            "host": ["{{base_url}}"]
                        }
                    },
                    "status": "OK",
                    "code": 200,
                    "_postman_previewlanguage": "json"
                })
        
        request_obj = {
            "name": translated_name,
            "request": {
                "method": "POST",
                "header": [{"key": "Content-Type", "value": "application/json"}],
                "body": {
                    "mode": "raw",
                    "raw": json.dumps(processed_data, indent=2)
                },
                "url": {
                    "raw": "{{base_url}}",
                    "host": ["{{base_url}}"]
                },
                "description": description
            },
            "response": examples,
            "event": []
        }
        
        # Add test for capturing task_id if this is an init request
        if method.endswith("::init") and "task_id" not in json.dumps(request_data):
            actual_task_var_name = self.get_task_variable_name(method)
            test_script = f"""
pm.test("Capture task_id", function () {{
    const responseJson = pm.response.json();
    if (responseJson.result && responseJson.result.task_id) {{
        pm.collectionVariables.set("{actual_task_var_name}", responseJson.result.task_id);
    }}
}});
"""
            request_obj["event"] = [{
                "listen": "test",
                "script": {
                    "exec": test_script.strip().split('\n'),
                    "type": "text/javascript"
                }
            }]
        
        return request_obj
    
    def _generate_environment_notes(self, environment: str, method: str) -> str:
        """Generate environment-specific notes for request description."""
        notes = "\n\n"
        
        if environment == 'wasm':
            notes += "**Environment Notes:**\n"
            notes += "- This request uses WebSocket Secure (WSS) protocols only\n"
            notes += "- Electrum servers are filtered to WSS-compatible endpoints\n"
        elif 'trezor' in environment:
            notes += "**Hardware Requirements:**\n"
            notes += "- This request requires Trezor hardware wallet\n"
        
        # Add protocol preferences
        base_env = environment.split('_')[0] if environment else 'native'
        protocol_prefs = self.env_manager.get_protocol_preferences(method, base_env)
        if protocol_prefs:
            notes += f"\n**Protocol Preferences:** {protocol_prefs}\n"
        
        return notes
    
    # ===== FOLDER STRUCTURE CREATION =====
    
    def create_folder_structure(self, requests: Dict[str, Dict], version: str, 
                              filename: str, tables: Dict[str, Dict],
                              environment: str = None) -> Dict:
        """Create folder structure for Postman collection organized by method paths."""
        folder_tree = {}
        
        # Group requests by method
        method_groups = {}
        for request_key, request_data in requests.items():
            method = request_data.get("method")
            if not method:
                continue
            
            # Check environment compatibility if specified
            if environment and environment != "standard":
                base_env = environment.split('_')[0]
                hardware = 'trezor' if 'trezor' in environment else None
                wallet_type = environment.split('_')[1] if '_' in environment and environment.split('_')[1] in ['hd', 'iguana'] else None
                
                if not self._is_request_compatible(request_key, method, base_env, hardware, wallet_type):
                    continue
            
            if method not in method_groups:
                method_groups[method] = []
            method_groups[method].append((request_key, request_data))
        
        # Process each method group
        for method, examples in method_groups.items():
            method_components = self.get_method_path_components(method)
            path_parts = [version.lower(), filename.lower()] + method_components
            
            # Navigate/create the nested structure
            current_level = folder_tree
            for i, part in enumerate(path_parts):
                if part not in current_level:
                    current_level[part] = {
                        "_folders": {},
                        "_items": []
                    }
                
                if i == len(path_parts) - 1:
                    # Last component - create request
                    primary_key, primary_data = examples[0]
                    
                    request_obj = self.create_postman_request(
                        primary_key, 
                        primary_data, 
                        version, 
                        tables,
                        examples if len(examples) > 1 else None,
                        environment
                    )
                    current_level[part]["_items"].append(request_obj)
                else:
                    current_level = current_level[part]["_folders"]
        
        return folder_tree
    
    def _is_request_compatible(self, request_key: str, method: str, 
                             environment: str, hardware: str = None, wallet_type: str = None) -> bool:
        """Check if a request is compatible with the target environment."""
        # Check method compatibility
        is_compatible, _ = self.env_manager.validate_method_compatibility(
            method, environment, hardware, wallet_type
        )
        
        if not is_compatible:
            return False
        
        # Check example-specific compatibility using pattern matching
        return self.env_manager._matches_pattern_requirements(
            request_key, environment, hardware, wallet_type
        )
    
    def convert_tree_to_postman_folders(self, tree: Dict, name: str = "") -> List[Dict]:
        """Convert the folder tree to Postman folder structure."""
        items = []
        
        for key, value in tree.items():
            if key.startswith("_"):
                continue
            
            folder_items = []
            
            if "_items" in value:
                folder_items.extend(value["_items"])
            
            if "_folders" in value:
                for subfolder_name, subfolder_data in value["_folders"].items():
                    subfolder_items = self.convert_tree_to_postman_folders({subfolder_name: subfolder_data}, subfolder_name)
                    folder_items.extend(subfolder_items)
            
            if folder_items:
                items.append({
                    "name": key,
                    "item": folder_items
                })
        
        return items
    
    # ===== COLLECTION GENERATION =====
    
    def generate_standard_collection(self) -> Dict:
        """Generate the standard comprehensive Postman collection."""
        tables = self.load_all_tables()
        folder_tree = {}
        
        # Process each version directory
        for version_dir in self.requests_dir.iterdir():
            if not version_dir.is_dir():
                continue
            
            version = version_dir.name
            logger.info(f"Processing version: {version}")
            
            # Process all JSON files in the version directory
            for json_file in version_dir.glob("*.json"):
                filename = json_file.stem
                logger.info(f"Processing file: {filename}")
                
                requests_data = self.load_json_file(json_file)
                if not requests_data:
                    continue
                
                # Filter out deprecated methods and validate
                filtered_requests_data = {}
                for request_key, request_data in requests_data.items():
                    method = request_data.get("method")
                    if method:
                        method_config = self.method_config.get(method, {})
                        if method_config.get('deprecated', False):
                            continue  # Skip deprecated methods
                    filtered_requests_data[request_key] = request_data
                
                # Validate and collect reports
                for request_key, request_data in filtered_requests_data.items():
                    method = request_data.get("method")
                    if method:
                        unused = self.validate_request_params(request_data, method, tables)
                        if unused:
                            self.unused_params[method] = list(unused)
                    
                    if not self.check_response_exists(request_key, version):
                        # Skip deprecated methods from missing responses report
                        method_config = self.method_config.get(method, {})
                        if not method_config.get('deprecated', False):
                            # Skip manual/external methods that can't be automated
                            if self._is_manual_method(request_key):
                                continue
                            if method not in self.missing_responses:
                                self.missing_responses[method] = []
                            self.missing_responses[method].append(request_key)
                
                # Add to folder tree (using filtered data)
                file_tree = self.create_folder_structure(filtered_requests_data, version, filename, tables, "standard")
                
                # Merge into main tree
                for key, value in file_tree.items():
                    if key not in folder_tree:
                        folder_tree[key] = value
                    else:
                        if "_folders" in value:
                            for subfolder_name, subfolder_data in value["_folders"].items():
                                if subfolder_name not in folder_tree[key]["_folders"]:
                                    folder_tree[key]["_folders"][subfolder_name] = subfolder_data
                        if "_items" in value:
                            folder_tree[key]["_items"].extend(value["_items"])
        
        # Convert tree to Postman folder structure
        all_folders = self.convert_tree_to_postman_folders(folder_tree)
        
        # Create collection variables
        variables = [
            {"key": "base_url", "value": "http://127.0.0.1:7783", "type": "string"},
            {"key": "userpass", "value": "RPC_UserP@SSW0RD", "type": "string"}
        ]
        
        # Add task ID variables
        for var_name, default_value in self.task_variables.items():
            variables.append({
                "key": var_name,
                "value": default_value,
                "type": "string"
            })
        
        # Create the collection
        collection = {
            "info": {
                "name": "Komodo DeFi Framework API",
                "description": "Comprehensive auto-generated Postman collection for KDF API",
                "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json",
                "_postman_id": str(uuid.uuid4())
            },
            "item": all_folders,
            "variable": variables
        }
        
        return collection
    
    def generate_environment_collection(self, environment: str) -> Dict[str, Any]:
        """Generate a Postman collection for a specific environment."""
        # Load and filter request data
        request_data = self.load_request_data('v2')
        
        # Filter out deprecated methods first
        filtered_request_data = {}
        for request_key, request_info in request_data.items():
            method = request_info.get('method')
            if method:
                method_config = self.method_config.get(method, {})
                if method_config.get('deprecated', False):
                    continue  # Skip deprecated methods
            filtered_request_data[request_key] = request_info
        
        filtered_data = self.filter_protocols_for_environment(filtered_request_data, environment)
        
        # Get environment configuration
        env_configs = self.env_manager.get_environment_specific_postman_configs()
        config = env_configs.get(environment, {})
        
        # Load tables for descriptions
        tables = self.load_all_tables()
        
        collection = {
            "info": {
                "name": config.get('name', f'KDF API ({environment.title()})'),
                "description": self._generate_collection_description(environment, config),
                "schema": "https://schema.getpostman.com/json/collection/v2.1.0/collection.json",
                "_postman_id": f"kdf-{environment}-{datetime.now().strftime('%Y%m%d')}"
            },
            "variable": [
                {
                    "key": "base_url",
                    "value": config.get('base_url', 'http://127.0.0.1:7783'),
                    "type": "string"
                },
                {
                    "key": "userpass",
                    "value": "RPC_UserP@SSW0RD",
                    "type": "string"
                }
            ],
            "item": []
        }
        
        # Group requests by method family
        method_groups = self._group_requests_by_method(filtered_data)
        
        for method_family, requests in method_groups.items():
            folder_item = {
                "name": method_family,
                "item": []
            }
            
            for request_key, request_body in requests.items():
                method = request_body.get('method', '')
                hardware = 'trezor' if 'trezor' in environment else None
                wallet_type = config.get('wallet_type', None)
                base_env = environment.split('_')[0]
                
                if self._is_request_compatible(request_key, method, base_env, hardware, wallet_type):
                    postman_request = self.create_postman_request(
                        request_key, request_body, 'v2', tables, None, environment
                    )
                    folder_item["item"].append(postman_request)
            
            if folder_item["item"]:
                collection["item"].append(folder_item)
        
        return collection
    
    def _generate_collection_description(self, environment: str, config: Dict) -> str:
        """Generate description for the collection."""
        description = config.get('description', f'KDF API for {environment} environment')
        notes = config.get('notes', '')
        
        protocol_info = ""
        if 'preferred_protocols' in config:
            protocols = config['preferred_protocols']
            protocol_details = []
            for proto_type, proto_list in protocols.items():
                protocol_details.append(f"{proto_type}: {', '.join(proto_list)}")
            protocol_info = f"\n\nSupported Protocols:\n- " + "\n- ".join(protocol_details)
        
        hardware_info = ""
        if 'hardware' in config:
            hardware_info = f"\n\nHardware Support: {', '.join(config['hardware'])}"
        
        return f"{description}\n\n{notes}{protocol_info}{hardware_info}"
    
    def _group_requests_by_method(self, request_data: Dict[str, Any]) -> Dict[str, Dict]:
        """Group requests by method family for better organization."""
        groups = {}
        
        for request_key, request_body in request_data.items():
            if not isinstance(request_body, dict):
                continue
            
            method = request_body.get('method', '')
            
            # Determine method family
            if method.startswith('task::enable_'):
                coin_type = method.split('::')[1].replace('enable_', '')
                family = f"Task Enable {coin_type.upper()}"
            elif method.startswith('enable_'):
                family = "Legacy Enable"
            else:
                family = "Other Methods"
            
            if family not in groups:
                groups[family] = {}
            
            groups[family][request_key] = request_body
        
        return groups
    
    # ===== REPORTS =====
    
    def save_reports(self, reports_dir: Path) -> None:
        """Save validation reports with consistent alphabetical sorting.
        
        Always writes all report files, even if empty, to indicate current state.
        """
        reports_dir.mkdir(parents=True, exist_ok=True)
        
        # Save unused parameters report (always)
        sorted_unused = {}
        if self.unused_params:
            for method in sorted(self.unused_params.keys()):
                sorted_unused[method] = sorted(self.unused_params[method])
        
        unused_file = reports_dir / "unused_params.json"
        with open(unused_file, 'w') as f:
            json.dump(sorted_unused, f, indent=2, sort_keys=True)
        logger.info(f"Unused parameters report saved to {unused_file}")
        
        # Save missing responses report (always)
        sorted_missing = {}
        if self.missing_responses:
            for method in sorted(self.missing_responses.keys()):
                sorted_missing[method] = sorted(self.missing_responses[method])
        
        missing_file = reports_dir / "missing_responses.json"
        with open(missing_file, 'w') as f:
            json.dump(sorted_missing, f, indent=2, sort_keys=True)
        logger.info(f"Missing responses report saved to {missing_file}")
        
        # Save untranslated keys report (always)
        untranslated_list = sorted(self.untranslated_keys) if self.untranslated_keys else []
        untranslated_file = reports_dir / "untranslated_keys.json"
        with open(untranslated_file, 'w') as f:
            json.dump(untranslated_list, f, indent=2)
        logger.info(f"Untranslated keys report saved to {untranslated_file}")
        
        # Save missing tables report (always)
        missing_tables_list = sorted(self.missing_tables) if self.missing_tables else []
        missing_tables_file = reports_dir / "missing_tables.json"
        with open(missing_tables_file, 'w') as f:
            json.dump(missing_tables_list, f, indent=2)
        logger.info(f"Missing tables report saved to {missing_tables_file}")
    
    # ===== SELF-REPAIR FUNCTIONALITY =====
    
    def discover_missing_methods(self) -> Dict[str, Dict]:
        """Discover methods in request files that are missing from method config."""
        missing_methods = {}
        
        # Scan all request files to find methods
        for version_dir in self.requests_dir.iterdir():
            if not version_dir.is_dir():
                continue
            
            for json_file in version_dir.glob("*.json"):
                requests_data = self.load_json_file(json_file)
                if not requests_data:
                    continue
                
                for request_key, request_data in requests_data.items():
                    method = request_data.get("method")
                    if method and method not in self.method_config:
                        # Check if method exists in config but is deprecated
                        existing_config = self.method_config.get(method, {})
                        if existing_config.get('deprecated', False):
                            continue  # Skip deprecated methods
                            
                        if method not in missing_methods:
                            missing_methods[method] = {
                                "examples": {},
                                "version": version_dir.name,
                                "file": json_file.stem
                            }
                        
                        # Infer a human-readable name for this example
                        example_name = self._infer_example_name(request_key, method)
                        missing_methods[method]["examples"][request_key] = example_name
        
        return missing_methods
    
    def _infer_example_name(self, request_key: str, method: str) -> str:
        """Infer a human-readable name for a request example."""
        # Remove common prefixes
        name = request_key
        
        # Convert CamelCase to Title Case with spaces
        import re
        name = re.sub(r'([A-Z])', r' \1', name).strip()
        
        # Clean up specific patterns
        name = name.replace("Enable ", "Enable ")
        name = name.replace("Task ", "")
        name = name.replace("Legacy ", "")
        
        # Add context based on method type
        if "enable_" in method:
            if "Init" in request_key:
                name = name.replace(" Init", " Initialization")
            elif "Status" in request_key:
                name = name.replace(" Status", " Status Check")
            elif "Cancel" in request_key:
                name = name.replace(" Cancel", " Cancellation")
            elif "UserAction" in request_key:
                if "Pin" in request_key:
                    name = name.replace(" User Action Pin", " (Trezor PIN)")
                else:
                    name = name.replace(" User Action", " User Action")
        
        return name
    
    def _infer_method_requirements(self, method: str, examples: Dict[str, str]) -> Dict[str, Any]:
        """Infer method requirements based on method name and examples."""
        requirements = {
            "environments": ["native", "wasm"],
            "wallet_types": ["hd", "iguana"]
        }
        
        # Infer environment and wallet compatibility based on method patterns
        
        # Stream methods are wasm-only
        if method.startswith("stream::"):
            requirements["environments"] = ["wasm"]
        
        # Trezor methods require hardware
        if "trezor" in method.lower() or "::user_action" in method.lower():
            requirements["wallet_types"] = ["trezor"]
        
        # Infer from example patterns
        for example_key in examples.keys():
            if "Trezor" in example_key:
                # Trezor examples indicate hardware wallet requirement
                requirements["wallet_types"] = ["trezor"]
            
            if "WalletConnect" in example_key:
                if "wallet_types" in requirements:
                    # WalletConnect typically works with both HD and iguana
                    pass
        
        return requirements
    
    def _infer_table_name(self, method: str) -> str:
        """Infer a table name based on method name."""
        # Convert method name to a table name
        table_name = method.replace("::", "_").replace("_", " ").title().replace(" ", "")
        table_name += "Arguments"
        return table_name
    
    def auto_repair_missing_methods(self, dry_run: bool = True) -> Dict[str, Any]:
        """Automatically repair missing method configurations."""
        missing_methods = self.discover_missing_methods()
        repair_plan = {
            "discovered_methods": len(missing_methods),
            "methods": {},
            "would_add": [] if not dry_run else list(missing_methods.keys())
        }
        
        if not missing_methods:
            logger.info("No missing methods discovered - configuration is complete!")
            return repair_plan
        
        logger.info(f"Discovered {len(missing_methods)} missing methods")
        
        for method, method_info in missing_methods.items():
            table_name = self._infer_table_name(method)
            requirements = self._infer_method_requirements(method, method_info["examples"])
            
            method_config = {
                "table": table_name,
                "examples": method_info["examples"],
                "requirements": requirements
            }
            
            repair_plan["methods"][method] = method_config
            
            if dry_run:
                logger.info(f"Would add method '{method}' with {len(method_info['examples'])} examples")
            else:
                self.method_config[method] = method_config
                logger.info(f"Added method '{method}' with {len(method_info['examples'])} examples")
        
        if not dry_run:
            self._save_method_config()
            logger.info(f"Saved updated method configuration with {len(missing_methods)} new methods")
        
        return repair_plan
    
    def _save_method_config(self):
        """Save the updated method configuration back to file."""
        config_file = self.workspace_root / "src" / "data" / "kdf_methods.json"
        
        # Sort the methods alphabetically for better organization
        sorted_config = dict(sorted(self.method_config.items()))
        
        with open(config_file, 'w') as f:
            json.dump(sorted_config, f, indent=2)
    
    # ===== MAIN GENERATION METHODS =====
    
    def _count_collection_items(self, collection_data: Dict) -> int:
        """Count the total number of requests in a collection."""
        count = 0
        
        def count_items(items):
            nonlocal count
            for item in items:
                if "request" in item:
                    count += 1
                elif "item" in item:
                    count_items(item["item"])
        
        if "item" in collection_data:
            count_items(collection_data["item"])
        
        return count
    
    def _count_report_items(self, report_data: Any) -> int:
        """Count items in a report based on its structure."""
        if isinstance(report_data, dict):
            # For reports like missing_responses and unused_params
            total = 0
            for key, value in report_data.items():
                if isinstance(value, list):
                    total += len(value)
                else:
                    total += 1
            return total
        elif isinstance(report_data, list):
            # For reports like untranslated_keys and missing_tables
            return len(report_data)
        else:
            return 1
    
    def generate_all_collections(self, output_dir: Path, auto_repair: bool = False) -> Dict[str, Dict]:
        """Generate all collection types."""
        generated_files = {}
        
        # Auto-repair missing method configurations if requested
        if auto_repair:
            logger.info("ðŸ”§ Running self-repair for missing method configurations...")
            repair_plan = self.auto_repair_missing_methods(dry_run=False)
            if repair_plan["discovered_methods"] > 0:
                logger.info(f"âœ… Auto-repaired {repair_plan['discovered_methods']} missing method configurations")
            else:
                logger.info("âœ… No missing method configurations found")
        
        # Create output directories
        standard_dir = output_dir / "collections"
        environments_dir = output_dir / "environments" 
        reports_dir = output_dir / "reports"
        
        standard_dir.mkdir(parents=True, exist_ok=True)
        environments_dir.mkdir(parents=True, exist_ok=True)
        
        # Generate standard collection
        logger.info("Generating standard comprehensive collection...")
        standard_collection = self.generate_standard_collection()
        
        standard_file = standard_dir / "kdf_comprehensive_collection.json"
        with open(standard_file, 'w') as f:
            json.dump(standard_collection, f, indent=2)
        
        # Count items in standard collection
        standard_count = self._count_collection_items(standard_collection)
        generated_files["standard"] = {
            "file": str(standard_file.relative_to(self.workspace_root)),
            "count": standard_count
        }
        logger.info(f"Standard collection saved to {standard_file}")
        
        # Generate environment-specific collections
        env_configs = self.env_manager.get_environment_specific_postman_configs()
        
        for environment in env_configs.keys():
            logger.info(f"Generating collection for environment: {environment}")
            
            env_collection = self.generate_environment_collection(environment)
            
            env_file = environments_dir / f"kdf_{environment}_collection.json"
            with open(env_file, 'w') as f:
                json.dump(env_collection, f, indent=2)
            
            # Count items in environment collection
            env_count = self._count_collection_items(env_collection)
            generated_files[environment] = {
                "file": str(env_file.relative_to(self.workspace_root)),
                "count": env_count
            }
            logger.info(f"Environment collection saved to {env_file}")
        
        # Save reports
        self.save_reports(reports_dir)
        
        # Prepare reports data with file paths and counts (always include all reports)
        reports_data = {}
        
        # Unused params (always)
        unused_params_file = reports_dir / "unused_params.json"
        reports_data["unused_params"] = {
            "file": str(unused_params_file.relative_to(self.workspace_root)),
            "count": self._count_report_items(self.unused_params) if self.unused_params else 0
        }
        
        # Missing responses (always)
        missing_responses_file = reports_dir / "missing_responses.json"
        reports_data["missing_responses"] = {
            "file": str(missing_responses_file.relative_to(self.workspace_root)),
            "count": self._count_report_items(self.missing_responses) if self.missing_responses else 0
        }
        
        # Untranslated keys (always)
        untranslated_keys_file = reports_dir / "untranslated_keys.json"
        reports_data["untranslated_keys"] = {
            "file": str(untranslated_keys_file.relative_to(self.workspace_root)),
            "count": len(self.untranslated_keys) if self.untranslated_keys else 0
        }
        
        # Missing tables (always)
        missing_tables_file = reports_dir / "missing_tables.json"
        reports_data["missing_tables"] = {
            "file": str(missing_tables_file.relative_to(self.workspace_root)),
            "count": len(self.missing_tables) if self.missing_tables else 0
        }
        
        # Generate summary
        summary = {
            "generation_timestamp": datetime.now().isoformat(),
            "generated_files": generated_files,
            "reports": reports_data
        }
        
        summary_file = output_dir / "generation_summary.json"
        with open(summary_file, 'w') as f:
            json.dump(summary, f, indent=2)
        
        return generated_files


def main():
    """Main CLI interface."""
    parser = argparse.ArgumentParser(
        description="Unified Postman Collection Generator for KDF API",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # Generate all collections (standard + all environments)
  python unified_postman_generator.py --all
  
  # Generate with auto-repair of missing method configurations
  python unified_postman_generator.py --all --auto-repair
  
  # Check what would be repaired without making changes
  python unified_postman_generator.py --dry-run-repair
  
  # Generate only standard comprehensive collection
  python unified_postman_generator.py --standard
  
  # Generate specific environment collection
  python unified_postman_generator.py --environment native_hd
  
  # Generate with custom output directory
  python unified_postman_generator.py --all --output-dir ./custom_output
  
  # Enable verbose logging
  python unified_postman_generator.py --all --verbose
        """
    )
    
    # Mode selection (mutually exclusive)
    mode_group = parser.add_mutually_exclusive_group(required=True)
    mode_group.add_argument(
        '--all', '-a',
        action='store_true',
        help="Generate all collections (standard + all environments)"
    )
    mode_group.add_argument(
        '--standard', '-s',
        action='store_true',
        help="Generate only the standard comprehensive collection"
    )
    mode_group.add_argument(
        '--environment', '-e',
        choices=['native_hd', 'native_iguana', 'wasm_hd', 'wasm_iguana', 'trezor_native_hd', 'trezor_wasm_hd'],
        help="Generate specific environment collection"
    )
    mode_group.add_argument(
        '--dry-run-repair',
        action='store_true',
        help="Show what would be repaired without making changes"
    )
    
    # Optional arguments
    parser.add_argument(
        '--workspace', '-w',
        help="Path to workspace root (auto-detected if not provided)"
    )
    parser.add_argument(
        '--output-dir', '-o',
        help="Output directory (default: postman/generated)"
    )
    parser.add_argument(
        '--verbose', '-v',
        action='store_true',
        help="Enable verbose output"
    )
    parser.add_argument(
        '--auto-repair',
        action='store_true',
        help="Automatically repair missing method configurations"
    )
    
    args = parser.parse_args()
    
    # Configure logging
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    
    try:
        generator = UnifiedPostmanGenerator(args.workspace)
        
        # Set output directory
        if args.output_dir:
            output_dir = Path(args.output_dir)
        else:
            output_dir = generator.workspace_root / "postman" / "generated"
        
        output_dir.mkdir(parents=True, exist_ok=True)
        
        # Handle dry-run repair mode
        if args.dry_run_repair:
            print("ðŸ” Checking for missing method configurations...")
            repair_plan = generator.auto_repair_missing_methods(dry_run=True)
            
            if repair_plan["discovered_methods"] == 0:
                print("âœ… No missing method configurations found!")
            else:
                print(f"ðŸ“‹ Found {repair_plan['discovered_methods']} missing method configurations:")
                for method in repair_plan["would_add"]:
                    examples_count = len(repair_plan["methods"][method]["examples"])
                    print(f"  â€¢ {method} (with {examples_count} examples)")
                print(f"\nTo apply these fixes, run with --auto-repair")
            return
        
        if args.all:
            print("ðŸš€ Generating all collections...")
            generated_files = generator.generate_all_collections(output_dir, auto_repair=args.auto_repair)
            
            print(f"\nâœ… Generated {len(generated_files)} collections:")
            for collection_type, file_info in generated_files.items():
                file_path = file_info["file"]
                count = file_info["count"]
                print(f"  {collection_type}: {file_path} ({count} requests)")
            
            print(f"\nðŸ“Š Summary: {output_dir / 'generation_summary.json'}")
            
        elif args.standard:
            print("ðŸš€ Generating standard comprehensive collection...")
            collection = generator.generate_standard_collection()
            
            collections_dir = output_dir / "collections"
            collections_dir.mkdir(parents=True, exist_ok=True)
            
            output_file = collections_dir / "kdf_comprehensive_collection.json"
            with open(output_file, 'w') as f:
                json.dump(collection, f, indent=2)
            
            # Save reports
            reports_dir = output_dir / "reports"
            generator.save_reports(reports_dir)
            
            print(f"âœ… Standard collection generated: {output_file}")
            print(f"ðŸ“Š Reports saved to: {reports_dir}")
            
        elif args.environment:
            print(f"ðŸš€ Generating collection for environment: {args.environment}")
            collection = generator.generate_environment_collection(args.environment)
            
            environments_dir = output_dir / "environments"
            environments_dir.mkdir(parents=True, exist_ok=True)
            
            output_file = environments_dir / f"kdf_{args.environment}_collection.json"
            with open(output_file, 'w') as f:
                json.dump(collection, f, indent=2)
            
            print(f"âœ… Environment collection generated: {output_file}")
    
    except Exception as e:
        print(f"âŒ Error: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()
        sys.exit(1)


if __name__ == "__main__":
    main()
